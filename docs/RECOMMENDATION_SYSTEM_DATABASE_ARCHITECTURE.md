# ä¼ä¸šçº§æ¨èç³»ç»Ÿæ•°æ®åº“æ¶æ„è®¾è®¡

## ğŸ¯ å½“å‰æ¶æ„ vs å®Œæ•´æ¨èç³»ç»Ÿæ¶æ„

### å½“å‰é¡¹ç›®æ•°æ®åº“ (åŸºç¡€ç‰ˆ)
```
Redis (ç‰¹å¾ç¼“å­˜) + SQLite (å…ƒæ•°æ®) + Parquet (æ‰¹å¤„ç†)
```

### å®Œæ•´æ¨èç³»ç»Ÿæ•°æ®åº“æ¶æ„ (ä¼ä¸šçº§)
```mermaid
graph TB
    subgraph "ç”¨æˆ·äº¤äº’å±‚ (æ¯«ç§’çº§)"
        A1[EVCache<br/>ç”¨æˆ·ä¼šè¯ç¼“å­˜]
        A2[Redis Cluster<br/>å®æ—¶ç‰¹å¾ç¼“å­˜]
        A3[Memcached<br/>è®¡ç®—ç»“æœç¼“å­˜]
    end
    
    subgraph "ä¸šåŠ¡æ•°æ®å±‚"
        B1[MongoDB<br/>ç”¨æˆ·ç”»åƒ]
        B2[Cassandra<br/>ç”¨æˆ·è¡Œä¸ºæ—¥å¿—]
        B3[HBase<br/>ç‰©å“ç‰¹å¾åº“]
        B4[DynamoDB<br/>å®æ—¶æ¨èç»“æœ]
    end
    
    subgraph "åˆ†æè®¡ç®—å±‚"
        C1[ClickHouse<br/>å®æ—¶åˆ†æ]
        C2[Elasticsearch<br/>æœç´¢å¬å›]
        C3[Neo4j<br/>å…³ç³»å›¾è°±]
        C4[TiDB<br/>HTAP æ··åˆè´Ÿè½½]
    end
    
    subgraph "å­˜å‚¨å½’æ¡£å±‚"
        D1[HDFS/S3<br/>åŸå§‹æ—¥å¿—]
        D2[Parquet/Delta Lake<br/>ç‰¹å¾å·¥ç¨‹]
        D3[Iceberg<br/>æ•°æ®æ¹–]
        D4[PostgreSQL<br/>ä¸šåŠ¡å…ƒæ•°æ®]
    end
    
    subgraph "æµå¤„ç†å±‚"
        E1[Kafka<br/>æ¶ˆæ¯é˜Ÿåˆ—]
        E2[Pulsar<br/>äº‹ä»¶æµ]
        E3[Redis Streams<br/>å®æ—¶æµ]
    end
    
    A1 --> B1
    A2 --> B2
    A3 --> B3
    B1 --> C1
    B2 --> C2
    B3 --> C3
    C1 --> D1
    C2 --> D2
    C3 --> D3
    E1 --> A2
    E2 --> B2
    E3 --> A1
```

## ğŸ“Š æ•°æ®åˆ†å±‚å­˜å‚¨ç­–ç•¥

### 1. çƒ­æ•°æ®å±‚ (Hot Tier) - æ¯«ç§’çº§è®¿é—®
```yaml
# EVCache é…ç½®
evcache:
  clusters:
    - name: "user-session"
      ttl: 1800  # 30åˆ†é’Ÿ
      replicas: 3
      memory_size: "16GB"
      use_cases:
        - ç”¨æˆ·ä¼šè¯çŠ¶æ€
        - å®æ—¶æ¨èç»“æœ
        - ç”¨æˆ·åå¥½ç¼“å­˜

# Redis Cluster é…ç½®  
redis_cluster:
  nodes: 6
  memory_per_node: "32GB"
  persistence: "rdb"
  use_cases:
    - å®æ—¶ç‰¹å¾å‘é‡
    - ç”¨æˆ·è¡Œä¸ºè®¡æ•°å™¨
    - çƒ­é—¨ç‰©å“ç¼“å­˜
```

### 2. æ¸©æ•°æ®å±‚ (Warm Tier) - ç§’çº§è®¿é—®
```yaml
# MongoDB é…ç½®
mongodb:
  replica_set: "rs0"
  sharding: true
  collections:
    user_profiles:
      shard_key: "user_id"
      indexes: ["user_id", "created_at", "tags"]
    item_catalog:
      shard_key: "item_id" 
      indexes: ["category", "brand", "price_range"]

# Cassandra é…ç½®
cassandra:
  keyspaces:
    user_behavior:
      replication_factor: 3
      tables:
        - user_clicks
        - user_purchases
        - user_ratings
        - user_views
```

### 3. å†·æ•°æ®å±‚ (Cold Tier) - åˆ†é’Ÿçº§è®¿é—®
```yaml
# ClickHouse é…ç½®
clickhouse:
  clusters:
    - name: "analytics"
      shards: 4
      replicas: 2
      tables:
        user_behavior_agg:
          engine: "ReplacingMergeTree"
          partition_by: "toYYYYMM(event_date)"
          order_by: "(user_id, event_date)"

# Elasticsearch é…ç½®
elasticsearch:
  indices:
    item_search:
      shards: 5
      replicas: 1
      mappings:
        title: {"type": "text", "analyzer": "ik_max_word"}
        category: {"type": "keyword"}
        embedding: {"type": "dense_vector", "dims": 768}
```

## ğŸ—ï¸ æ•°æ®åº“é€‰å‹åŸåˆ™

### æŒ‰æ•°æ®ç±»å‹åˆ†ç±»

#### 1. ç”¨æˆ·æ•°æ®
```python
# ç”¨æˆ·åŸºç¡€ä¿¡æ¯ - MongoDB
user_profile = {
    "user_id": "12345",
    "demographics": {
        "age": 28,
        "gender": "F",
        "location": "Chicago"
    },
    "preferences": {
        "categories": ["electronics", "books"],
        "brands": ["Apple", "Samsung"],
        "price_range": [100, 1000]
    },
    "behavior_summary": {
        "total_purchases": 45,
        "avg_order_value": 156.78,
        "last_active": "2024-01-15T10:30:00Z"
    }
}

# ç”¨æˆ·è¡Œä¸ºåºåˆ— - Cassandra
user_behavior = {
    "user_id": "12345",
    "timestamp": "2024-01-15T10:30:00Z",
    "event_type": "click",
    "item_id": "item_789",
    "context": {
        "page": "homepage",
        "position": 3,
        "device": "mobile"
    }
}
```

#### 2. ç‰©å“æ•°æ®
```python
# ç‰©å“ç‰¹å¾ - HBase
item_features = {
    "row_key": "item_789",
    "basic_info": {
        "title": "iPhone 15 Pro",
        "category": "electronics",
        "brand": "Apple",
        "price": 999.99
    },
    "computed_features": {
        "popularity_score": 0.85,
        "quality_score": 0.92,
        "embedding": [0.1, 0.2, ..., 0.8]  # 768ç»´å‘é‡
    },
    "stats": {
        "view_count": 15420,
        "purchase_count": 892,
        "rating_avg": 4.6
    }
}

# ç‰©å“æœç´¢ç´¢å¼• - Elasticsearch
item_search_doc = {
    "item_id": "item_789",
    "title": "iPhone 15 Pro 256GB æ·±ç©ºé»‘è‰²",
    "category": "æ‰‹æœº",
    "brand": "Apple",
    "price": 999.99,
    "tags": ["5G", "Pro", "æ‘„å½±"],
    "embedding": [0.1, 0.2, ..., 0.8],
    "popularity": 0.85
}
```

#### 3. å…³ç³»æ•°æ®
```python
# ç”¨æˆ·-ç‰©å“å…³ç³»å›¾ - Neo4j
cypher_query = """
CREATE (u:User {user_id: '12345', age: 28})
CREATE (i:Item {item_id: 'item_789', category: 'electronics'})
CREATE (u)-[:PURCHASED {timestamp: '2024-01-15', rating: 5}]->(i)
CREATE (u)-[:SIMILAR_TO {similarity: 0.85}]->(u2:User {user_id: '67890'})
"""

# ååŒè¿‡æ»¤çŸ©é˜µ - TiDB
user_item_matrix = """
CREATE TABLE user_item_interactions (
    user_id BIGINT,
    item_id BIGINT,
    interaction_type ENUM('view', 'click', 'purchase', 'rating'),
    score DECIMAL(3,2),
    timestamp TIMESTAMP,
    INDEX idx_user (user_id),
    INDEX idx_item (item_id),
    INDEX idx_time (timestamp)
) PARTITION BY RANGE (UNIX_TIMESTAMP(timestamp)) (
    PARTITION p202401 VALUES LESS THAN (UNIX_TIMESTAMP('2024-02-01')),
    PARTITION p202402 VALUES LESS THAN (UNIX_TIMESTAMP('2024-03-01'))
);
"""
```

## âš¡ ç¼“å­˜ç­–ç•¥è®¾è®¡

### å¤šçº§ç¼“å­˜æ¶æ„
```python
class MultiLevelCache:
    """å¤šçº§ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        # L1: EVCache (æœ€çƒ­æ•°æ®)
        self.l1_cache = EVCacheClient(
            app_name="recommendation",
            cache_prefix="rec_",
            ttl=300  # 5åˆ†é’Ÿ
        )
        
        # L2: Redis (çƒ­æ•°æ®)
        self.l2_cache = RedisCluster(
            nodes=[
                {"host": "redis-1", "port": 6379},
                {"host": "redis-2", "port": 6379},
                {"host": "redis-3", "port": 6379}
            ],
            ttl=3600  # 1å°æ—¶
        )
        
        # L3: MongoDB (æ¸©æ•°æ®)
        self.l3_cache = MongoClient(
            "mongodb://mongo-cluster:27017/recommendation"
        )
    
    async def get_user_recommendations(self, user_id: str) -> List[Dict]:
        """è·å–ç”¨æˆ·æ¨è - å¤šçº§ç¼“å­˜ç­–ç•¥"""
        
        # L1 ç¼“å­˜æŸ¥æ‰¾
        cache_key = f"user_rec_{user_id}"
        result = await self.l1_cache.get(cache_key)
        if result:
            return result
        
        # L2 ç¼“å­˜æŸ¥æ‰¾
        result = await self.l2_cache.get(cache_key)
        if result:
            # å›å¡« L1 ç¼“å­˜
            await self.l1_cache.set(cache_key, result, ttl=300)
            return result
        
        # L3 æ•°æ®åº“æŸ¥æ‰¾
        result = await self.l3_cache.find_one(
            {"user_id": user_id}, 
            {"recommendations": 1}
        )
        
        if result:
            recommendations = result["recommendations"]
            # å›å¡«å¤šçº§ç¼“å­˜
            await self.l2_cache.set(cache_key, recommendations, ttl=3600)
            await self.l1_cache.set(cache_key, recommendations, ttl=300)
            return recommendations
        
        return []
```

## ğŸ”„ æ•°æ®æµè½¬æ¶æ„

### å®æ—¶æ•°æ®æµ
```python
# Kafka æ¶ˆæ¯ç”Ÿäº§è€…
class RecommendationEventProducer:
    """æ¨èç³»ç»Ÿäº‹ä»¶ç”Ÿäº§è€…"""
    
    def __init__(self):
        self.producer = KafkaProducer(
            bootstrap_servers=['kafka-1:9092', 'kafka-2:9092'],
            value_serializer=lambda x: json.dumps(x).encode('utf-8')
        )
    
    async def send_user_behavior(self, event: Dict):
        """å‘é€ç”¨æˆ·è¡Œä¸ºäº‹ä»¶"""
        # å‘é€åˆ°ä¸åŒä¸»é¢˜
        topics = {
            'click': 'user-clicks',
            'purchase': 'user-purchases', 
            'view': 'user-views',
            'rating': 'user-ratings'
        }
        
        topic = topics.get(event['event_type'], 'user-behaviors')
        await self.producer.send(topic, value=event)
    
    async def send_model_update(self, model_metrics: Dict):
        """å‘é€æ¨¡å‹æ›´æ–°äº‹ä»¶"""
        await self.producer.send('model-updates', value=model_metrics)

# æµå¤„ç†æ¶ˆè´¹è€…
class RecommendationStreamProcessor:
    """æ¨èç³»ç»Ÿæµå¤„ç†å™¨"""
    
    def __init__(self):
        self.consumer = KafkaConsumer(
            'user-behaviors',
            bootstrap_servers=['kafka-1:9092'],
            group_id='recommendation-processor'
        )
        
        # æ•°æ®åº“è¿æ¥
        self.cassandra = CassandraCluster(['cassandra-1', 'cassandra-2'])
        self.redis = RedisCluster(nodes=[...])
        self.mongodb = MongoClient("mongodb://mongo-cluster:27017")
    
    async def process_user_behavior(self, event: Dict):
        """å¤„ç†ç”¨æˆ·è¡Œä¸ºäº‹ä»¶"""
        user_id = event['user_id']
        item_id = event['item_id']
        
        # 1. å†™å…¥ Cassandra (ç”¨æˆ·è¡Œä¸ºæ—¥å¿—)
        await self.cassandra.execute(
            "INSERT INTO user_behavior (user_id, item_id, event_type, timestamp) VALUES (?, ?, ?, ?)",
            [user_id, item_id, event['event_type'], event['timestamp']]
        )
        
        # 2. æ›´æ–° Redis (å®æ—¶è®¡æ•°å™¨)
        await self.redis.incr(f"item_views:{item_id}")
        await self.redis.incr(f"user_actions:{user_id}")
        
        # 3. æ›´æ–° MongoDB (ç”¨æˆ·ç”»åƒ)
        await self.mongodb.recommendation.user_profiles.update_one(
            {"user_id": user_id},
            {"$inc": {"behavior_stats.total_actions": 1}},
            upsert=True
        )
        
        # 4. è§¦å‘å®æ—¶æ¨èæ›´æ–°
        await self.update_real_time_recommendations(user_id)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### æ•°æ®åº“æ€§èƒ½å¯¹æ¯”
| æ•°æ®åº“ | è¯»å»¶è¿Ÿ | å†™å»¶è¿Ÿ | ååé‡ | é€‚ç”¨åœºæ™¯ |
|--------|--------|--------|--------|----------|
| **EVCache** | <1ms | <1ms | 1M+ QPS | ç”¨æˆ·ä¼šè¯ |
| **Redis Cluster** | 1-5ms | 1-5ms | 500K QPS | å®æ—¶ç‰¹å¾ |
| **MongoDB** | 5-20ms | 5-20ms | 100K QPS | ç”¨æˆ·ç”»åƒ |
| **Cassandra** | 10-50ms | 1-10ms | 1M+ WPS | è¡Œä¸ºæ—¥å¿— |
| **ClickHouse** | 100ms-1s | 100ms-1s | 1B+ rows/s | å®æ—¶åˆ†æ |
| **Elasticsearch** | 10-100ms | 50-200ms | 50K QPS | æœç´¢å¬å› |

### åˆ†ç‰‡ç­–ç•¥
```python
# ç”¨æˆ·æ•°æ®åˆ†ç‰‡ç­–ç•¥
def get_user_shard(user_id: str) -> str:
    """æ ¹æ®ç”¨æˆ·IDè®¡ç®—åˆ†ç‰‡"""
    shard_count = 16
    shard_id = hash(user_id) % shard_count
    return f"user_shard_{shard_id:02d}"

# ç‰©å“æ•°æ®åˆ†ç‰‡ç­–ç•¥  
def get_item_shard(item_id: str) -> str:
    """æ ¹æ®ç‰©å“IDè®¡ç®—åˆ†ç‰‡"""
    shard_count = 32
    shard_id = hash(item_id) % shard_count
    return f"item_shard_{shard_id:02d}"

# æ—¶é—´åˆ†ç‰‡ç­–ç•¥
def get_time_partition(timestamp: datetime) -> str:
    """æ ¹æ®æ—¶é—´è®¡ç®—åˆ†åŒº"""
    return f"p{timestamp.strftime('%Y%m')}"
```

## ğŸš€ éƒ¨ç½²æ¶æ„

### Kubernetes éƒ¨ç½²æ¸…å•
```yaml
# evcache-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: evcache-cluster
spec:
  replicas: 3
  selector:
    matchLabels:
      app: evcache
  template:
    metadata:
      labels:
        app: evcache
    spec:
      containers:
      - name: evcache
        image: netflix/evcache:latest
        ports:
        - containerPort: 11211
        env:
        - name: CACHE_SIZE
          value: "16g"
        - name: MAX_CONNECTIONS
          value: "10000"
        resources:
          requests:
            memory: "18Gi"
            cpu: "4"
          limits:
            memory: "20Gi"
            cpu: "8"

---
# mongodb-cluster.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mongodb-cluster
spec:
  serviceName: mongodb
  replicas: 3
  selector:
    matchLabels:
      app: mongodb
  template:
    metadata:
      labels:
        app: mongodb
    spec:
      containers:
      - name: mongodb
        image: mongo:6.0
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: "admin"
        - name: MONGO_INITDB_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mongodb-secret
              key: password
        volumeMounts:
        - name: mongodb-storage
          mountPath: /data/db
        resources:
          requests:
            memory: "8Gi"
            cpu: "2"
          limits:
            memory: "16Gi"
            cpu: "4"
  volumeClaimTemplates:
  - metadata:
      name: mongodb-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
```

## ğŸ’¡ æ€»ç»“

å®Œæ•´çš„æ¨èç³»ç»Ÿæ•°æ®åº“æ¶æ„åº”è¯¥åŒ…å«ï¼š

### å¿…éœ€ç»„ä»¶
1. **EVCache/Memcached** - è¶…ä½å»¶è¿Ÿç¼“å­˜
2. **Redis Cluster** - å®æ—¶ç‰¹å¾å­˜å‚¨
3. **MongoDB/DynamoDB** - ç”¨æˆ·ç”»åƒå­˜å‚¨
4. **Cassandra/HBase** - å¤§è§„æ¨¡è¡Œä¸ºæ—¥å¿—
5. **ClickHouse** - å®æ—¶åˆ†æOLAP
6. **Elasticsearch** - æœç´¢å’Œå¬å›
7. **Neo4j** - å…³ç³»å›¾è°±
8. **Kafka/Pulsar** - å®æ—¶æ•°æ®æµ

### å½“å‰é¡¹ç›®å¯ä»¥æ‰©å±•çš„æ–¹å‘
- ğŸš€ å¼•å…¥ EVCache æå‡ç¼“å­˜æ€§èƒ½
- ğŸ“Š æ·»åŠ  MongoDB å­˜å‚¨ç”¨æˆ·ç”»åƒ
- ğŸ” é›†æˆ Elasticsearch æ”¯æŒæœç´¢å¬å›
- ğŸ“ˆ éƒ¨ç½² ClickHouse è¿›è¡Œå®æ—¶åˆ†æ
- ğŸ•¸ï¸ ä½¿ç”¨ Neo4j æ„å»ºå…³ç³»å›¾è°±

è¿™æ ·çš„æ¶æ„æ‰èƒ½æ”¯æ’‘**ç™¾ä¸‡çº§ç”¨æˆ·ã€åƒä¸‡çº§ç‰©å“**çš„ä¼ä¸šçº§æ¨èç³»ç»Ÿï¼ğŸ¯
