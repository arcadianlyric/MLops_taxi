#!/usr/bin/env python3
"""
Streamlit UI ä¸ Kafka æµå¤„ç†é›†æˆ
å®æ—¶æ˜¾ç¤º Chicago Taxi æµå¤„ç†ç»“æœ
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import threading
import time
from datetime import datetime, timedelta
from collections import deque
import asyncio
from typing import Dict, List, Any

# å¯¼å…¥æµå¤„ç†å™¨
from kafka_stream_processor import KafkaStreamProcessor, TaxiPrediction, ModelMetric


class StreamlitKafkaIntegration:
    """Streamlit ä¸ Kafka æµå¤„ç†é›†æˆç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–é›†æˆç»„ä»¶"""
        self.processor = KafkaStreamProcessor()
        
        # æ•°æ®ç¼“å­˜ï¼ˆä½¿ç”¨ deque ä¿æŒæœ€è¿‘çš„æ•°æ®ï¼‰
        self.predictions_buffer = deque(maxlen=100)
        self.metrics_buffer = deque(maxlen=50)
        self.ride_stats = {
            'total_rides': 0,
            'total_revenue': 0.0,
            'avg_fare': 0.0,
            'avg_tip': 0.0
        }
        
        # å¯åŠ¨åå°æ•°æ®æ¶ˆè´¹çº¿ç¨‹
        self._start_background_consumers()
    
    def _start_background_consumers(self):
        """å¯åŠ¨åå°æ•°æ®æ¶ˆè´¹çº¿ç¨‹"""
        
        def consume_predictions():
            """æ¶ˆè´¹é¢„æµ‹ç»“æœ"""
            def prediction_callback(prediction: TaxiPrediction):
                self.predictions_buffer.append({
                    'trip_id': prediction.trip_id,
                    'timestamp': prediction.timestamp,
                    'predicted_fare': prediction.predicted_fare,
                    'predicted_tip': prediction.predicted_tip,
                    'confidence': prediction.confidence_score,
                    'model_version': prediction.model_version
                })
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.ride_stats['total_rides'] += 1
                self.ride_stats['total_revenue'] += prediction.predicted_fare
                self.ride_stats['avg_fare'] = self.ride_stats['total_revenue'] / self.ride_stats['total_rides']
                
                # è®¡ç®—å¹³å‡å°è´¹
                tips = [p['predicted_tip'] for p in list(self.predictions_buffer)]
                self.ride_stats['avg_tip'] = sum(tips) / len(tips) if tips else 0.0
            
            self.processor.consume_predictions_for_ui(prediction_callback)
        
        def consume_metrics():
            """æ¶ˆè´¹æŒ‡æ ‡æ•°æ®"""
            consumer = self.processor._get_consumer(
                self.processor.topics['metrics'], 
                'streamlit-metrics-group'
            )
            
            for message in consumer:
                try:
                    metric_data = message.value
                    self.metrics_buffer.append(metric_data)
                except Exception as e:
                    st.error(f"æ¶ˆè´¹æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
        
        # å¯åŠ¨åå°çº¿ç¨‹
        prediction_thread = threading.Thread(target=consume_predictions)
        prediction_thread.daemon = True
        prediction_thread.start()
        
        metrics_thread = threading.Thread(target=consume_metrics)
        metrics_thread.daemon = True
        metrics_thread.start()
    
    def render_real_time_dashboard(self):
        """æ¸²æŸ“å®æ—¶ä»ªè¡¨æ¿"""
        st.header("ğŸŒŠ å®æ—¶æ•°æ®æµç›‘æ§")
        
        # æ§åˆ¶é¢æ¿
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.subheader("ğŸ“Š å®æ—¶æµå¤„ç†çŠ¶æ€")
        
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", key="refresh_stream"):
                st.rerun()
        
        with col3:
            auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (5ç§’)", key="auto_refresh_stream")
        
        # è‡ªåŠ¨åˆ·æ–°é€»è¾‘
        if auto_refresh:
            time.sleep(5)
            st.rerun()
        
        # å®æ—¶ç»Ÿè®¡æ¦‚è§ˆ
        self._render_real_time_stats()
        
        st.divider()
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        stream_tab1, stream_tab2, stream_tab3, stream_tab4 = st.tabs([
            "ğŸš• å®æ—¶é¢„æµ‹", "ğŸ“ˆ æµå¤„ç†æŒ‡æ ‡", "ğŸ”„ æ•°æ®æµçŠ¶æ€", "âš¡ æ€§èƒ½ç›‘æ§"
        ])
        
        with stream_tab1:
            self._render_real_time_predictions()
        
        with stream_tab2:
            self._render_stream_metrics()
        
        with stream_tab3:
            self._render_data_flow_status()
        
        with stream_tab4:
            self._render_performance_monitoring()
    
    def _render_real_time_stats(self):
        """æ¸²æŸ“å®æ—¶ç»Ÿè®¡æ¦‚è§ˆ"""
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                "æ€»è¡Œç¨‹æ•°",
                f"{self.ride_stats['total_rides']:,}",
                delta=f"+{len(self.predictions_buffer)}" if self.predictions_buffer else None
            )
        
        with col2:
            st.metric(
                "æ€»æ”¶å…¥",
                f"${self.ride_stats['total_revenue']:.2f}",
                delta=f"+${self.predictions_buffer[-1]['predicted_fare']:.2f}" if self.predictions_buffer else None
            )
        
        with col3:
            st.metric(
                "å¹³å‡è½¦è´¹",
                f"${self.ride_stats['avg_fare']:.2f}"
            )
        
        with col4:
            st.metric(
                "å¹³å‡å°è´¹",
                f"${self.ride_stats['avg_tip']:.2f}"
            )
    
    def _render_real_time_predictions(self):
        """æ¸²æŸ“å®æ—¶é¢„æµ‹ç»“æœ"""
        st.subheader("ğŸš• å®æ—¶é¢„æµ‹ç»“æœ")
        
        if not self.predictions_buffer:
            st.info("ç­‰å¾…å®æ—¶é¢„æµ‹æ•°æ®...")
            
            # æä¾›æ¨¡æ‹Ÿæ•°æ®æŒ‰é’®
            if st.button("ğŸ² ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®", key="generate_mock_stream"):
                with st.spinner("ç”Ÿæˆæ¨¡æ‹Ÿæµæ•°æ®..."):
                    self.processor.simulate_taxi_rides(5)
                    time.sleep(2)
                    st.success("æ¨¡æ‹Ÿæ•°æ®å·²å‘é€åˆ° Kafka æµï¼")
            return
        
        # æœ€è¿‘é¢„æµ‹è¡¨æ ¼
        recent_predictions = list(self.predictions_buffer)[-10:]  # æœ€è¿‘10æ¡
        df_predictions = pd.DataFrame(recent_predictions)
        
        st.dataframe(
            df_predictions[['trip_id', 'predicted_fare', 'predicted_tip', 'confidence']],
            use_container_width=True
        )
        
        # å®æ—¶é¢„æµ‹è¶‹åŠ¿å›¾
        if len(recent_predictions) > 1:
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=('å®æ—¶è½¦è´¹é¢„æµ‹', 'å®æ—¶å°è´¹é¢„æµ‹'),
                vertical_spacing=0.1
            )
            
            timestamps = [datetime.fromisoformat(p['timestamp'].replace('Z', '+00:00')) for p in recent_predictions]
            
            # è½¦è´¹è¶‹åŠ¿
            fig.add_trace(
                go.Scatter(
                    x=timestamps,
                    y=[p['predicted_fare'] for p in recent_predictions],
                    mode='lines+markers',
                    name='é¢„æµ‹è½¦è´¹',
                    line=dict(color='blue')
                ),
                row=1, col=1
            )
            
            # å°è´¹è¶‹åŠ¿
            fig.add_trace(
                go.Scatter(
                    x=timestamps,
                    y=[p['predicted_tip'] for p in recent_predictions],
                    mode='lines+markers',
                    name='é¢„æµ‹å°è´¹',
                    line=dict(color='green')
                ),
                row=2, col=1
            )
            
            fig.update_layout(height=500, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_stream_metrics(self):
        """æ¸²æŸ“æµå¤„ç†æŒ‡æ ‡"""
        st.subheader("ğŸ“ˆ æµå¤„ç†æŒ‡æ ‡")
        
        if not self.metrics_buffer:
            st.info("ç­‰å¾…æµå¤„ç†æŒ‡æ ‡æ•°æ®...")
            return
        
        # æŒ‡æ ‡æ•°æ®å¤„ç†
        metrics_data = list(self.metrics_buffer)
        df_metrics = pd.DataFrame(metrics_data)
        
        if df_metrics.empty:
            st.warning("æš‚æ— æŒ‡æ ‡æ•°æ®")
            return
        
        # æŒ‰æŒ‡æ ‡ç±»å‹åˆ†ç»„æ˜¾ç¤º
        metric_types = df_metrics['metric_name'].unique()
        
        for metric_type in metric_types:
            metric_data = df_metrics[df_metrics['metric_name'] == metric_type]
            
            if len(metric_data) > 1:
                fig = px.line(
                    metric_data,
                    x='timestamp',
                    y='metric_value',
                    title=f'{metric_type} è¶‹åŠ¿',
                    markers=True
                )
                
                # æ·»åŠ é˜ˆå€¼çº¿
                if 'threshold' in metric_data.columns:
                    threshold = metric_data['threshold'].iloc[0]
                    fig.add_hline(
                        y=threshold,
                        line_dash="dash",
                        line_color="red",
                        annotation_text=f"é˜ˆå€¼: {threshold}"
                    )
                
                st.plotly_chart(fig, use_container_width=True)
    
    def _render_data_flow_status(self):
        """æ¸²æŸ“æ•°æ®æµçŠ¶æ€"""
        st.subheader("ğŸ”„ æ•°æ®æµçŠ¶æ€")
        
        # Kafka Topics çŠ¶æ€
        topics_status = {
            "taxi-rides-raw": "ğŸŸ¢ æ´»è·ƒ",
            "taxi-features-realtime": "ğŸŸ¢ æ´»è·ƒ",
            "taxi-predictions": "ğŸŸ¢ æ´»è·ƒ",
            "model-metrics": "ğŸŸ¡ ä¸­ç­‰",
            "data-quality-alerts": "ğŸŸ¢ æ´»è·ƒ"
        }
        
        st.subheader("ğŸ“‹ Kafka Topics çŠ¶æ€")
        for topic, status in topics_status.items():
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"**{topic}**")
            with col2:
                st.write(status)
        
        # æµå¤„ç†å™¨çŠ¶æ€
        st.subheader("âš™ï¸ æµå¤„ç†å™¨çŠ¶æ€")
        processors_status = {
            "ç‰¹å¾å·¥ç¨‹å¤„ç†å™¨": "ğŸŸ¢ è¿è¡Œä¸­",
            "æ¨¡å‹æ¨ç†å¤„ç†å™¨": "ğŸŸ¢ è¿è¡Œä¸­",
            "æŒ‡æ ‡è®¡ç®—å¤„ç†å™¨": "ğŸŸ¢ è¿è¡Œä¸­",
            "å¼‚å¸¸æ£€æµ‹å¤„ç†å™¨": "ğŸŸ¡ å¾…å¯åŠ¨"
        }
        
        for processor, status in processors_status.items():
            col1, col2 = st.columns([3, 1])
            with col1:
                st.write(f"**{processor}**")
            with col2:
                st.write(status)
    
    def _render_performance_monitoring(self):
        """æ¸²æŸ“æ€§èƒ½ç›‘æ§"""
        st.subheader("âš¡ æ€§èƒ½ç›‘æ§")
        
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
        performance_data = {
            "æ¶ˆæ¯å¤„ç†å»¶è¿Ÿ": "23ms",
            "ååé‡": "1,250 msg/sec",
            "é”™è¯¯ç‡": "0.02%",
            "å†…å­˜ä½¿ç”¨": "245MB",
            "CPU ä½¿ç”¨": "15%"
        }
        
        col1, col2 = st.columns(2)
        
        with col1:
            for metric, value in list(performance_data.items())[:3]:
                st.metric(metric, value)
        
        with col2:
            for metric, value in list(performance_data.items())[3:]:
                st.metric(metric, value)
        
        # æ€§èƒ½è¶‹åŠ¿å›¾ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰
        if self.predictions_buffer:
            timestamps = [datetime.now() - timedelta(minutes=i) for i in range(10, 0, -1)]
            latencies = [20 + i * 2 + (i % 3) * 5 for i in range(10)]
            throughputs = [1200 + i * 50 + (i % 2) * 100 for i in range(10)]
            
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=('å¤„ç†å»¶è¿Ÿ (ms)', 'ååé‡ (msg/sec)'),
                vertical_spacing=0.1
            )
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=latencies, mode='lines+markers', name='å»¶è¿Ÿ'),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=throughputs, mode='lines+markers', name='ååé‡'),
                row=2, col=1
            )
            
            fig.update_layout(height=400, showlegend=False)
            st.plotly_chart(fig, use_container_width=True)
    
    def render_stream_control_panel(self):
        """æ¸²æŸ“æµæ§åˆ¶é¢æ¿"""
        st.sidebar.header("ğŸ›ï¸ æµå¤„ç†æ§åˆ¶")
        
        # å¯åŠ¨/åœæ­¢æ§åˆ¶
        if st.sidebar.button("ğŸš€ å¯åŠ¨æ‰€æœ‰å¤„ç†å™¨"):
            with st.spinner("å¯åŠ¨æµå¤„ç†å™¨..."):
                self.processor.start_all_processors()
                st.sidebar.success("æµå¤„ç†å™¨å·²å¯åŠ¨ï¼")
        
        if st.sidebar.button("â¹ï¸ åœæ­¢æ‰€æœ‰å¤„ç†å™¨"):
            with st.spinner("åœæ­¢æµå¤„ç†å™¨..."):
                self.processor.close()
                st.sidebar.success("æµå¤„ç†å™¨å·²åœæ­¢ï¼")
        
        st.sidebar.divider()
        
        # æ•°æ®ç”Ÿæˆæ§åˆ¶
        st.sidebar.subheader("ğŸ“Š æ•°æ®ç”Ÿæˆ")
        
        num_rides = st.sidebar.slider("ç”Ÿæˆè¡Œç¨‹æ•°é‡", 1, 50, 10)
        
        if st.sidebar.button("ğŸ² ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"):
            with st.spinner(f"ç”Ÿæˆ {num_rides} ä¸ªæ¨¡æ‹Ÿè¡Œç¨‹..."):
                self.processor.simulate_taxi_rides(num_rides)
                st.sidebar.success(f"å·²ç”Ÿæˆ {num_rides} ä¸ªæ¨¡æ‹Ÿè¡Œç¨‹ï¼")
        
        st.sidebar.divider()
        
        # é…ç½®é€‰é¡¹
        st.sidebar.subheader("âš™ï¸ é…ç½®")
        
        kafka_server = st.sidebar.text_input(
            "Kafka æœåŠ¡å™¨",
            value="localhost:9092"
        )
        
        api_endpoint = st.sidebar.text_input(
            "API ç«¯ç‚¹",
            value="http://localhost:8000"
        )
        
        if st.sidebar.button("ğŸ”„ é‡æ–°è¿æ¥"):
            self.processor = KafkaStreamProcessor(kafka_server)
            st.sidebar.success("å·²é‡æ–°è¿æ¥åˆ° Kafkaï¼")


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="Chicago Taxi å®æ—¶æµå¤„ç†",
        page_icon="ğŸŒŠ",
        layout="wide"
    )
    
    # åˆå§‹åŒ–é›†æˆç»„ä»¶
    if 'kafka_integration' not in st.session_state:
        st.session_state.kafka_integration = StreamlitKafkaIntegration()
    
    integration = st.session_state.kafka_integration
    
    # æ¸²æŸ“æ§åˆ¶é¢æ¿
    integration.render_stream_control_panel()
    
    # æ¸²æŸ“ä¸»ä»ªè¡¨æ¿
    integration.render_real_time_dashboard()
    
    # æ·»åŠ è¯´æ˜
    with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ğŸŒŠ å®æ—¶æµå¤„ç†åŠŸèƒ½è¯´æ˜
        
        **æ•°æ®æµç¨‹ï¼š**
        1. ğŸ“¡ **æ•°æ®é‡‡é›†**: æ¨¡æ‹Ÿå‡ºç§Ÿè½¦è¡Œç¨‹æ•°æ®å‘é€åˆ° Kafka
        2. ğŸ”§ **ç‰¹å¾å·¥ç¨‹**: å®æ—¶è®¡ç®—è¡Œç¨‹ç‰¹å¾ï¼ˆè·ç¦»ã€æ—¶é—´ã€åŒºåŸŸç­‰ï¼‰
        3. ğŸ¤– **æ¨¡å‹æ¨ç†**: è°ƒç”¨ FastAPI æœåŠ¡è¿›è¡Œè´¹ç”¨å’Œå°è´¹é¢„æµ‹
        4. ğŸ“Š **æŒ‡æ ‡è®¡ç®—**: è®¡ç®—æ¨¡å‹æ€§èƒ½å’Œä¸šåŠ¡æŒ‡æ ‡
        5. ğŸ“ˆ **å®æ—¶å±•ç¤º**: åœ¨ Streamlit UI ä¸­å®æ—¶æ˜¾ç¤ºç»“æœ
        
        **æ“ä½œæ­¥éª¤ï¼š**
        1. ç‚¹å‡»ä¾§è¾¹æ "ğŸš€ å¯åŠ¨æ‰€æœ‰å¤„ç†å™¨"å¯åŠ¨æµå¤„ç†
        2. ç‚¹å‡»"ğŸ² ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"å‘é€æµ‹è¯•æ•°æ®
        3. è§‚å¯Ÿå„ä¸ªæ ‡ç­¾é¡µä¸­çš„å®æ—¶æ•°æ®æ›´æ–°
        4. å¯ç”¨"è‡ªåŠ¨åˆ·æ–°"è·å¾—æœ€ä½³ä½“éªŒ
        
        **æ³¨æ„äº‹é¡¹ï¼š**
        - ç¡®ä¿ Kafka æœåŠ¡å™¨åœ¨ localhost:9092 è¿è¡Œ
        - ç¡®ä¿ FastAPI æœåŠ¡åœ¨ localhost:8000 è¿è¡Œ
        - é¦–æ¬¡å¯åŠ¨å¯èƒ½éœ€è¦å‡ ç§’é’Ÿåˆå§‹åŒ–æ—¶é—´
        """)


if __name__ == "__main__":
    main()
