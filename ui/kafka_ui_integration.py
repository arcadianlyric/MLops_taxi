#!/usr/bin/env python3
"""
Streamlit UI Kafka æµå¤„ç†é›†æˆæ¨¡å—
ä¸º Streamlit åº”ç”¨æä¾› Kafka æµå¤„ç†çš„å¯è§†åŒ–å’Œç®¡ç†åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import requests
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging


class KafkaUIIntegration:
    """Kafka UI é›†æˆç±»"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000"):
        self.api_base_url = api_base_url
        self.logger = logging.getLogger(__name__)
    
    def render_kafka_dashboard(self):
        """æ¸²æŸ“ Kafka æµå¤„ç†ä»ªè¡¨æ¿"""
        
        st.header("ğŸš€ Kafka æµå¤„ç†ç³»ç»Ÿ")
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tabs = st.tabs([
            "ğŸ“Š é›†ç¾¤æ¦‚è§ˆ", 
            "ğŸ“‹ ä¸»é¢˜ç®¡ç†", 
            "ğŸŒŠ æµå¤„ç†å™¨", 
            "ğŸ“¤ æ¶ˆæ¯å‘é€",
            "ğŸ§ª æ•°æ®ç”Ÿæˆ",
            "ğŸ“ˆ å®æ—¶ç›‘æ§"
        ])
        
        with tabs[0]:
            self._render_cluster_overview()
        
        with tabs[1]:
            self._render_topic_management()
        
        with tabs[2]:
            self._render_stream_processors()
        
        with tabs[3]:
            self._render_message_sender()
        
        with tabs[4]:
            self._render_data_generator()
        
        with tabs[5]:
            self._render_realtime_monitoring()
    
    def _render_cluster_overview(self):
        """æ¸²æŸ“é›†ç¾¤æ¦‚è§ˆ"""
        
        st.subheader("ğŸ“Š Kafka é›†ç¾¤æ¦‚è§ˆ")
        
        try:
            response = requests.get(f"{self.api_base_url}/kafka/info")
            
            if response.status_code == 200:
                cluster_info = response.json()["data"]
                
                # æ˜¾ç¤ºè¿æ¥çŠ¶æ€
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    kafka_status = "ğŸŸ¢ å·²è¿æ¥" if cluster_info.get("client_connected", False) else "ğŸ”´ æœªè¿æ¥"
                    st.metric("Kafka çŠ¶æ€", kafka_status)
                
                with col2:
                    availability = "ğŸŸ¢ å¯ç”¨" if cluster_info.get("kafka_available", False) else "ğŸ”´ ä¸å¯ç”¨"
                    st.metric("Kafka å¯ç”¨æ€§", availability)
                
                with col3:
                    servers = ", ".join(cluster_info.get("bootstrap_servers", []))
                    st.metric("Bootstrap æœåŠ¡å™¨", servers)
                
                with col4:
                    status = cluster_info.get("status", "unknown")
                    status_icon = "ğŸŸ¢" if status == "connected" else "ğŸ”´"
                    st.metric("æ•´ä½“çŠ¶æ€", f"{status_icon} {status}")
                
                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                st.subheader("ğŸ“‹ é›†ç¾¤è¯¦ç»†ä¿¡æ¯")
                
                cluster_details = pd.DataFrame([
                    {"å±æ€§": "Kafka å¯ç”¨", "å€¼": str(cluster_info.get("kafka_available", False))},
                    {"å±æ€§": "å®¢æˆ·ç«¯è¿æ¥", "å€¼": str(cluster_info.get("client_connected", False))},
                    {"å±æ€§": "Bootstrap æœåŠ¡å™¨", "å€¼": ", ".join(cluster_info.get("bootstrap_servers", []))},
                    {"å±æ€§": "è¿æ¥çŠ¶æ€", "å€¼": cluster_info.get("status", "unknown")}
                ])
                
                st.dataframe(cluster_details, use_container_width=True)
                
            else:
                st.error("æ— æ³•è·å–é›†ç¾¤ä¿¡æ¯")
                
        except Exception as e:
            st.error(f"è·å–é›†ç¾¤æ¦‚è§ˆå¤±è´¥: {e}")
    
    def _render_topic_management(self):
        """æ¸²æŸ“ä¸»é¢˜ç®¡ç†"""
        
        st.subheader("ğŸ“‹ Kafka ä¸»é¢˜ç®¡ç†")
        
        try:
            response = requests.get(f"{self.api_base_url}/kafka/topics")
            
            if response.status_code == 200:
                topics = response.json()["data"]
                
                if topics:
                    # åˆ›å»ºä¸»é¢˜è¡¨æ ¼
                    topic_data = []
                    for topic in topics:
                        topic_data.append({
                            "ä¸»é¢˜åç§°": topic.get("name", ""),
                            "åˆ†åŒºæ•°": topic.get("partitions", 0),
                            "å‰¯æœ¬å› å­": topic.get("replication_factor", 0),
                            "çŠ¶æ€": topic.get("status", "unknown"),
                            "å‹ç¼©ç±»å‹": topic.get("config", {}).get("compression.type", "none")
                        })
                    
                    topics_df = pd.DataFrame(topic_data)
                    st.dataframe(topics_df, use_container_width=True)
                    
                    # ä¸»é¢˜è¯¦æƒ…
                    st.subheader("ğŸ“Š ä¸»é¢˜è¯¦æƒ…")
                    
                    selected_topic = st.selectbox(
                        "é€‰æ‹©ä¸»é¢˜æŸ¥çœ‹è¯¦æƒ…",
                        options=[topic["name"] for topic in topics],
                        key="topic_selector"
                    )
                    
                    if selected_topic:
                        self._show_topic_details(selected_topic)
                
                else:
                    st.info("æš‚æ— ä¸»é¢˜")
                    
            else:
                st.error("æ— æ³•è·å–ä¸»é¢˜åˆ—è¡¨")
                
        except Exception as e:
            st.error(f"è·å–ä¸»é¢˜ç®¡ç†ä¿¡æ¯å¤±è´¥: {e}")
    
    def _show_topic_details(self, topic_name: str):
        """æ˜¾ç¤ºä¸»é¢˜è¯¦æƒ…"""
        try:
            response = requests.get(f"{self.api_base_url}/kafka/topics/{topic_name}")
            
            if response.status_code == 200:
                topic_info = response.json()["data"]
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**åŸºæœ¬ä¿¡æ¯:**")
                    st.write(f"- ä¸»é¢˜åç§°: {topic_info.get('name', 'N/A')}")
                    st.write(f"- åˆ†åŒºæ•°: {topic_info.get('partitions', 'N/A')}")
                    st.write(f"- å‰¯æœ¬å› å­: {topic_info.get('replication_factor', 'N/A')}")
                    st.write(f"- çŠ¶æ€: {topic_info.get('status', 'N/A')}")
                
                with col2:
                    st.write("**é…ç½®ä¿¡æ¯:**")
                    config = topic_info.get("config", {})
                    for key, value in config.items():
                        if key in ["cleanup.policy", "retention.ms", "compression.type"]:
                            st.write(f"- {key}: {value}")
            
            else:
                st.error(f"æ— æ³•è·å–ä¸»é¢˜ {topic_name} çš„è¯¦æƒ…")
                
        except Exception as e:
            st.error(f"è·å–ä¸»é¢˜è¯¦æƒ…å¤±è´¥: {e}")
    
    def _render_stream_processors(self):
        """æ¸²æŸ“æµå¤„ç†å™¨çŠ¶æ€"""
        
        st.subheader("ğŸŒŠ æµå¤„ç†å™¨çŠ¶æ€")
        
        try:
            response = requests.get(f"{self.api_base_url}/kafka/stream-processors")
            
            if response.status_code == 200:
                processors = response.json()["data"]
                
                if processors:
                    # å¤„ç†å™¨çŠ¶æ€æ¦‚è§ˆ
                    col1, col2, col3, col4 = st.columns(4)
                    
                    total_processors = len(processors)
                    running_processors = len([p for p in processors if p["status"] == "running"])
                    total_messages = sum(p["messages_processed"] for p in processors)
                    avg_rate = np.mean([p["processing_rate"] for p in processors])
                    
                    with col1:
                        st.metric("æ€»å¤„ç†å™¨æ•°", total_processors)
                    
                    with col2:
                        st.metric("è¿è¡Œä¸­", running_processors)
                    
                    with col3:
                        st.metric("æ€»å¤„ç†æ¶ˆæ¯", f"{total_messages:,}")
                    
                    with col4:
                        st.metric("å¹³å‡å¤„ç†é€Ÿç‡", f"{avg_rate:.1f} msg/s")
                    
                    # å¤„ç†å™¨è¯¦æƒ…è¡¨æ ¼
                    st.subheader("ğŸ“Š å¤„ç†å™¨è¯¦æƒ…")
                    
                    processor_data = []
                    for proc in processors:
                        processor_data.append({
                            "å¤„ç†å™¨åç§°": proc.get("processor_name", ""),
                            "çŠ¶æ€": proc.get("status", ""),
                            "å·²å¤„ç†æ¶ˆæ¯": f"{proc.get('messages_processed', 0):,}",
                            "å¤„ç†é€Ÿç‡": f"{proc.get('processing_rate', 0):.1f} msg/s",
                            "é”™è¯¯æ•°": proc.get("error_count", 0)
                        })
                    
                    processors_df = pd.DataFrame(processor_data)
                    st.dataframe(processors_df, use_container_width=True)
                
                else:
                    st.info("æš‚æ— æµå¤„ç†å™¨")
                    
            else:
                st.error("æ— æ³•è·å–æµå¤„ç†å™¨çŠ¶æ€")
                
        except Exception as e:
            st.error(f"è·å–æµå¤„ç†å™¨çŠ¶æ€å¤±è´¥: {e}")
    
    def _render_message_sender(self):
        """æ¸²æŸ“æ¶ˆæ¯å‘é€ç•Œé¢"""
        
        st.subheader("ğŸ“¤ æ¶ˆæ¯å‘é€")
        
        # å‡ºç§Ÿè½¦æ•°æ®å‘é€
        st.write("**å‘é€å‡ºç§Ÿè½¦è¡Œç¨‹æ•°æ®**")
        
        col1, col2 = st.columns(2)
        
        with col1:
            trip_id = st.text_input("è¡Œç¨‹ID", value=f"trip_{int(time.time())}", key="taxi_trip_id")
            pickup_lat = st.number_input("ä¸Šè½¦çº¬åº¦", value=41.88, format="%.6f", key="taxi_pickup_lat")
            pickup_lon = st.number_input("ä¸Šè½¦ç»åº¦", value=-87.63, format="%.6f", key="taxi_pickup_lon")
            passenger_count = st.number_input("ä¹˜å®¢æ•°", value=2, min_value=1, max_value=6, key="taxi_passengers")
        
        with col2:
            trip_distance = st.number_input("è¡Œç¨‹è·ç¦»", value=3.5, min_value=0.1, format="%.2f", key="taxi_distance")
            fare_amount = st.number_input("è½¦è´¹", value=12.50, min_value=2.25, format="%.2f", key="taxi_fare")
            payment_type = st.selectbox("æ”¯ä»˜æ–¹å¼", ["Credit Card", "Cash", "No Charge"], key="taxi_payment")
            company = st.selectbox("å‡ºç§Ÿè½¦å…¬å¸", ["Flash Cab", "Yellow Cab", "Blue Diamond"], key="taxi_company")
        
        if st.button("ğŸš• å‘é€å‡ºç§Ÿè½¦æ•°æ®", key="send_taxi"):
            try:
                pickup_time = datetime.now()
                dropoff_time = pickup_time + timedelta(minutes=np.random.randint(5, 60))
                
                taxi_data = {
                    "trip_id": trip_id,
                    "pickup_datetime": pickup_time.isoformat(),
                    "dropoff_datetime": dropoff_time.isoformat(),
                    "pickup_latitude": pickup_lat,
                    "pickup_longitude": pickup_lon,
                    "dropoff_latitude": pickup_lat + np.random.uniform(-0.01, 0.01),
                    "dropoff_longitude": pickup_lon + np.random.uniform(-0.01, 0.01),
                    "passenger_count": passenger_count,
                    "trip_distance": trip_distance,
                    "fare_amount": fare_amount,
                    "payment_type": payment_type,
                    "company": company
                }
                
                response = requests.post(
                    f"{self.api_base_url}/kafka/messages/taxi-data",
                    json=taxi_data
                )
                
                if response.status_code == 200:
                    st.success("âœ… å‡ºç§Ÿè½¦æ•°æ®å‘é€æˆåŠŸï¼")
                    st.json(response.json())
                else:
                    st.error(f"âŒ å‘é€å¤±è´¥: {response.text}")
                    
            except Exception as e:
                st.error(f"âŒ å‘é€å¤±è´¥: {e}")
    
    def _render_data_generator(self):
        """æ¸²æŸ“æ•°æ®ç”Ÿæˆå™¨"""
        
        st.subheader("ğŸ§ª æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨")
        
        col1, col2 = st.columns(2)
        
        with col1:
            count = st.number_input("ç”Ÿæˆæ•°æ®æ¡æ•°", value=50, min_value=1, max_value=1000, key="gen_count")
            
        with col2:
            rate = st.number_input("å‘é€é€Ÿç‡ (æ¡/ç§’)", value=2.0, min_value=0.1, max_value=100.0, key="gen_rate")
        
        estimated_time = count / rate
        st.info(f"é¢„ä¼°ç”Ÿæˆæ—¶é—´: {estimated_time:.1f} ç§’")
        
        if st.button("ğŸ² å¼€å§‹ç”Ÿæˆæµ‹è¯•æ•°æ®", key="start_generator"):
            try:
                response = requests.post(
                    f"{self.api_base_url}/kafka/generate-test-data",
                    params={"count": count, "rate": rate}
                )
                
                if response.status_code == 200:
                    result = response.json()["data"]
                    st.success("âœ… æµ‹è¯•æ•°æ®ç”Ÿæˆå·²å¯åŠ¨ï¼")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ•°æ®æ¡æ•°", result["count"])
                    with col2:
                        st.metric("å‘é€é€Ÿç‡", f"{result['rate']} æ¡/ç§’")
                    with col3:
                        st.metric("é¢„è®¡æ—¶é•¿", f"{result['estimated_duration']:.1f} ç§’")
                    
                    st.info("æ•°æ®æ­£åœ¨åå°ç”Ÿæˆå¹¶å‘é€åˆ° taxi-raw-data ä¸»é¢˜")
                else:
                    st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {response.text}")
                    
            except Exception as e:
                st.error(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
    
    def _render_realtime_monitoring(self):
        """æ¸²æŸ“å®æ—¶ç›‘æ§"""
        
        st.subheader("ğŸ“ˆ å®æ—¶æµå¤„ç†ç›‘æ§")
        
        # è‡ªåŠ¨åˆ·æ–°æ§åˆ¶
        auto_refresh = st.checkbox("è‡ªåŠ¨åˆ·æ–° (30ç§’)", value=False, key="auto_refresh")
        
        if auto_refresh:
            time.sleep(30)
            st.rerun()
        
        # åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°", key="manual_refresh"):
            st.rerun()
        
        # æ¨¡æ‹Ÿå®æ—¶æ•°æ®
        monitoring_data = self._generate_monitoring_data()
        
        # å®æ—¶æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»æ¶ˆæ¯æ•°", f"{monitoring_data['total_messages']:,}")
        
        with col2:
            st.metric("å¤„ç†é€Ÿç‡", f"{monitoring_data['processing_rate']:.1f} msg/s")
        
        with col3:
            st.metric("é”™è¯¯ç‡", f"{monitoring_data['error_rate']:.2%}")
        
        with col4:
            st.metric("å»¶è¿Ÿ", f"{monitoring_data['latency']:.1f} ms")
        
        # å®æ—¶å›¾è¡¨
        col1, col2 = st.columns(2)
        
        with col1:
            # æ¶ˆæ¯ååé‡å›¾è¡¨
            fig_throughput = go.Figure()
            fig_throughput.add_trace(go.Scatter(
                x=monitoring_data['timeline'],
                y=monitoring_data['throughput'],
                mode='lines+markers',
                name='ååé‡',
                line=dict(color='blue')
            ))
            fig_throughput.update_layout(
                title="æ¶ˆæ¯ååé‡è¶‹åŠ¿",
                xaxis_title="æ—¶é—´",
                yaxis_title="æ¶ˆæ¯æ•°/ç§’"
            )
            st.plotly_chart(fig_throughput, use_container_width=True)
        
        with col2:
            # å»¶è¿Ÿå›¾è¡¨
            fig_latency = go.Figure()
            fig_latency.add_trace(go.Scatter(
                x=monitoring_data['timeline'],
                y=monitoring_data['latency_trend'],
                mode='lines+markers',
                name='å»¶è¿Ÿ',
                line=dict(color='red')
            ))
            fig_latency.update_layout(
                title="å¤„ç†å»¶è¿Ÿè¶‹åŠ¿",
                xaxis_title="æ—¶é—´",
                yaxis_title="å»¶è¿Ÿ (ms)"
            )
            st.plotly_chart(fig_latency, use_container_width=True)
    
    def _generate_monitoring_data(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿç›‘æ§æ•°æ®"""
        
        # ç”Ÿæˆæ—¶é—´åºåˆ—
        now = datetime.now()
        timeline = [now - timedelta(minutes=i) for i in range(30, 0, -1)]
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        throughput = [np.random.uniform(10, 100) for _ in timeline]
        latency_trend = [np.random.uniform(20, 200) for _ in timeline]
        
        return {
            'total_messages': np.random.randint(10000, 100000),
            'processing_rate': np.random.uniform(50, 150),
            'error_rate': np.random.uniform(0, 0.05),
            'latency': np.random.uniform(30, 100),
            'timeline': timeline,
            'throughput': throughput,
            'latency_trend': latency_trend
        }


# å…¨å±€å®ä¾‹
kafka_ui = KafkaUIIntegration()
