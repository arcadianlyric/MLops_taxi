#!/usr/bin/env python3
"""
Streamlit UI MLflow æ¨¡å‹æ³¨å†Œä¸­å¿ƒé›†æˆæ¨¡å—
ä¸º Streamlit åº”ç”¨æä¾› MLflow æ¨¡å‹ç®¡ç†çš„å¯è§†åŒ–åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import requests
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging


class MLflowUIIntegration:
    """MLflow UI é›†æˆç±»"""
    
    def __init__(self, api_base_url: str = "http://localhost:8000"):
        """
        åˆå§‹åŒ– MLflow UI é›†æˆ
        
        Args:
            api_base_url: FastAPI æœåŠ¡åŸºç¡€URL
        """
        self.api_base_url = api_base_url
        self.logger = logging.getLogger(__name__)
    
    def render_mlflow_dashboard(self):
        """æ¸²æŸ“ MLflow æ¨¡å‹æ³¨å†Œä¸­å¿ƒä»ªè¡¨æ¿"""
        
        st.header("ğŸ¯ MLflow æ¨¡å‹æ³¨å†Œä¸­å¿ƒ")
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        tabs = st.tabs([
            "ğŸ“Š æœåŠ¡æ¦‚è§ˆ",
            "ğŸ§ª å®éªŒç®¡ç†", 
            "ğŸ“¦ æ¨¡å‹æ³¨å†Œ",
            "ğŸ”„ æ¨¡å‹ç‰ˆæœ¬",
            "ğŸ“ˆ æ¨¡å‹æŒ‡æ ‡",
            "ğŸš€ æ¨¡å‹é¢„æµ‹"
        ])
        
        with tabs[0]:
            self._render_service_overview()
        
        with tabs[1]:
            self._render_experiment_management()
        
        with tabs[2]:
            self._render_model_registry()
        
        with tabs[3]:
            self._render_model_versions()
        
        with tabs[4]:
            self._render_model_metrics()
        
        with tabs[5]:
            self._render_model_prediction()
    
    def _render_service_overview(self):
        """æ¸²æŸ“æœåŠ¡æ¦‚è§ˆ"""
        
        st.subheader("ğŸ“Š MLflow æœåŠ¡æ¦‚è§ˆ")
        
        try:
            # è·å–æœåŠ¡ä¿¡æ¯
            response = requests.get(f"{self.api_base_url}/mlflow/info")
            
            if response.status_code == 200:
                service_info = response.json()["data"]
                
                # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    mlflow_status = "ğŸŸ¢ å¯ç”¨" if service_info.get("mlflow_available", False) else "ğŸ”´ ä¸å¯ç”¨"
                    st.metric("MLflow å¯ç”¨æ€§", mlflow_status)
                
                with col2:
                    client_status = "ğŸŸ¢ å·²è¿æ¥" if service_info.get("client_connected", False) else "ğŸ”´ æœªè¿æ¥"
                    st.metric("å®¢æˆ·ç«¯çŠ¶æ€", client_status)
                
                with col3:
                    tracking_uri = service_info.get("tracking_uri", "N/A")
                    st.metric("Tracking URI", tracking_uri)
                
                with col4:
                    status = service_info.get("status", "unknown")
                    status_icon = "ğŸŸ¢" if status == "connected" else "ğŸ”´"
                    st.metric("æ•´ä½“çŠ¶æ€", f"{status_icon} {status}")
                
                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                st.subheader("ğŸ“‹ æœåŠ¡è¯¦ç»†ä¿¡æ¯")
                
                service_details = pd.DataFrame([
                    {"å±æ€§": "MLflow å¯ç”¨", "å€¼": str(service_info.get("mlflow_available", False))},
                    {"å±æ€§": "å®¢æˆ·ç«¯è¿æ¥", "å€¼": str(service_info.get("client_connected", False))},
                    {"å±æ€§": "Tracking URI", "å€¼": service_info.get("tracking_uri", "N/A")},
                    {"å±æ€§": "æœåŠ¡çŠ¶æ€", "å€¼": service_info.get("status", "unknown")}
                ])
                
                st.dataframe(service_details, use_container_width=True)
                
            else:
                st.error("æ— æ³•è·å–æœåŠ¡ä¿¡æ¯")
                
        except Exception as e:
            st.error(f"è·å–æœåŠ¡æ¦‚è§ˆå¤±è´¥: {e}")
    
    def _render_experiment_management(self):
        """æ¸²æŸ“å®éªŒç®¡ç†"""
        
        st.subheader("ğŸ§ª å®éªŒç®¡ç†")
        
        # è·å–å®éªŒåˆ—è¡¨
        try:
            response = requests.get(f"{self.api_base_url}/mlflow/experiments")
            
            if response.status_code == 200:
                experiments = response.json()["data"]
                
                if experiments:
                    # å®éªŒæ¦‚è§ˆ
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("æ€»å®éªŒæ•°", len(experiments))
                    
                    with col2:
                        active_experiments = len([e for e in experiments if e.get("lifecycle_stage") == "active"])
                        st.metric("æ´»è·ƒå®éªŒ", active_experiments)
                    
                    with col3:
                        # è®¡ç®—æœ€è¿‘æ›´æ–°æ—¶é—´
                        if experiments:
                            latest_update = max(e.get("last_update_time", 0) for e in experiments)
                            latest_date = datetime.fromtimestamp(latest_update / 1000).strftime("%Y-%m-%d")
                            st.metric("æœ€è¿‘æ›´æ–°", latest_date)
                    
                    # å®éªŒåˆ—è¡¨
                    st.subheader("ğŸ“‹ å®éªŒåˆ—è¡¨")
                    
                    experiment_data = []
                    for exp in experiments:
                        creation_time = datetime.fromtimestamp(exp.get("creation_time", 0) / 1000)
                        last_update = datetime.fromtimestamp(exp.get("last_update_time", 0) / 1000)
                        
                        experiment_data.append({
                            "å®éªŒID": exp.get("experiment_id", ""),
                            "å®éªŒåç§°": exp.get("name", ""),
                            "ç”Ÿå‘½å‘¨æœŸ": exp.get("lifecycle_stage", ""),
                            "åˆ›å»ºæ—¶é—´": creation_time.strftime("%Y-%m-%d %H:%M"),
                            "æœ€åæ›´æ–°": last_update.strftime("%Y-%m-%d %H:%M"),
                            "æ ‡ç­¾æ•°": len(exp.get("tags", {}))
                        })
                    
                    experiments_df = pd.DataFrame(experiment_data)
                    st.dataframe(experiments_df, use_container_width=True)
                    
                    # å®éªŒè¯¦æƒ…
                    selected_exp = st.selectbox(
                        "é€‰æ‹©å®éªŒæŸ¥çœ‹è¯¦æƒ…",
                        options=[exp["name"] for exp in experiments],
                        key="exp_selector"
                    )
                    
                    if selected_exp:
                        exp_info = next(e for e in experiments if e["name"] == selected_exp)
                        self._show_experiment_details(exp_info)
                
                else:
                    st.info("æš‚æ— å®éªŒ")
                    
            else:
                st.error("æ— æ³•è·å–å®éªŒåˆ—è¡¨")
                
        except Exception as e:
            st.error(f"è·å–å®éªŒç®¡ç†ä¿¡æ¯å¤±è´¥: {e}")
        
        # åˆ›å»ºæ–°å®éªŒ
        self._render_create_experiment_form()
    
    def _show_experiment_details(self, experiment: Dict[str, Any]):
        """æ˜¾ç¤ºå®éªŒè¯¦æƒ…"""
        
        st.subheader(f"ğŸ“Š å®éªŒè¯¦æƒ…: {experiment['name']}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**åŸºæœ¬ä¿¡æ¯:**")
            st.write(f"- å®éªŒID: {experiment.get('experiment_id', 'N/A')}")
            st.write(f"- ç”Ÿå‘½å‘¨æœŸ: {experiment.get('lifecycle_stage', 'N/A')}")
            st.write(f"- å­˜å‚¨ä½ç½®: {experiment.get('artifact_location', 'N/A')}")
        
        with col2:
            st.write("**æ ‡ç­¾ä¿¡æ¯:**")
            tags = experiment.get("tags", {})
            if tags:
                for key, value in tags.items():
                    st.write(f"- {key}: {value}")
            else:
                st.write("- æ— æ ‡ç­¾")
    
    def _render_create_experiment_form(self):
        """æ¸²æŸ“åˆ›å»ºå®éªŒè¡¨å•"""
        
        st.subheader("â• åˆ›å»ºæ–°å®éªŒ")
        
        with st.form("create_experiment_form"):
            exp_name = st.text_input("å®éªŒåç§°", placeholder="ä¾‹å¦‚: taxi-model-v2")
            exp_description = st.text_area("å®éªŒæè¿°", placeholder="æè¿°å®éªŒç›®çš„å’Œå†…å®¹")
            
            # æ ‡ç­¾è¾“å…¥
            st.write("**å®éªŒæ ‡ç­¾:**")
            col1, col2 = st.columns(2)
            with col1:
                tag_key = st.text_input("æ ‡ç­¾é”®", placeholder="ä¾‹å¦‚: model_type")
            with col2:
                tag_value = st.text_input("æ ‡ç­¾å€¼", placeholder="ä¾‹å¦‚: regression")
            
            submitted = st.form_submit_button("ğŸš€ åˆ›å»ºå®éªŒ")
            
            if submitted and exp_name:
                try:
                    tags = {}
                    if tag_key and tag_value:
                        tags[tag_key] = tag_value
                    
                    payload = {
                        "name": exp_name,
                        "description": exp_description,
                        "tags": tags
                    }
                    
                    response = requests.post(
                        f"{self.api_base_url}/mlflow/experiments",
                        json=payload
                    )
                    
                    if response.status_code == 200:
                        st.success(f"âœ… å®éªŒ '{exp_name}' åˆ›å»ºæˆåŠŸï¼")
                        st.rerun()
                    else:
                        st.error(f"âŒ åˆ›å»ºå¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"âŒ åˆ›å»ºå®éªŒå¤±è´¥: {e}")
    
    def _render_model_registry(self):
        """æ¸²æŸ“æ¨¡å‹æ³¨å†Œ"""
        
        st.subheader("ğŸ“¦ æ¨¡å‹æ³¨å†Œä¸­å¿ƒ")
        
        try:
            response = requests.get(f"{self.api_base_url}/mlflow/models")
            
            if response.status_code == 200:
                models = response.json()["data"]
                
                if models:
                    # æ¨¡å‹æ¦‚è§ˆ
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric("æ³¨å†Œæ¨¡å‹æ•°", len(models))
                    
                    with col2:
                        production_models = sum(
                            1 for model in models 
                            for version in model.get("latest_versions", [])
                            if version.get("stage") == "Production"
                        )
                        st.metric("ç”Ÿäº§æ¨¡å‹", production_models)
                    
                    with col3:
                        staging_models = sum(
                            1 for model in models 
                            for version in model.get("latest_versions", [])
                            if version.get("stage") == "Staging"
                        )
                        st.metric("æµ‹è¯•æ¨¡å‹", staging_models)
                    
                    with col4:
                        total_versions = sum(len(model.get("latest_versions", [])) for model in models)
                        st.metric("æ€»ç‰ˆæœ¬æ•°", total_versions)
                    
                    # æ¨¡å‹åˆ—è¡¨
                    st.subheader("ğŸ“‹ æ³¨å†Œæ¨¡å‹åˆ—è¡¨")
                    
                    model_data = []
                    for model in models:
                        latest_versions = model.get("latest_versions", [])
                        production_version = next(
                            (v["version"] for v in latest_versions if v["stage"] == "Production"),
                            "æ— "
                        )
                        staging_version = next(
                            (v["version"] for v in latest_versions if v["stage"] == "Staging"),
                            "æ— "
                        )
                        
                        creation_time = datetime.fromtimestamp(
                            model.get("creation_timestamp", 0) / 1000
                        ).strftime("%Y-%m-%d")
                        
                        model_data.append({
                            "æ¨¡å‹åç§°": model.get("name", ""),
                            "æè¿°": model.get("description", "")[:50] + "..." if len(model.get("description", "")) > 50 else model.get("description", ""),
                            "ç”Ÿäº§ç‰ˆæœ¬": production_version,
                            "æµ‹è¯•ç‰ˆæœ¬": staging_version,
                            "æ€»ç‰ˆæœ¬æ•°": len(latest_versions),
                            "åˆ›å»ºæ—¶é—´": creation_time
                        })
                    
                    models_df = pd.DataFrame(model_data)
                    st.dataframe(models_df, use_container_width=True)
                    
                    # æ¨¡å‹è¯¦æƒ…
                    selected_model = st.selectbox(
                        "é€‰æ‹©æ¨¡å‹æŸ¥çœ‹è¯¦æƒ…",
                        options=[model["name"] for model in models],
                        key="model_selector"
                    )
                    
                    if selected_model:
                        model_info = next(m for m in models if m["name"] == selected_model)
                        self._show_model_details(model_info)
                
                else:
                    st.info("æš‚æ— æ³¨å†Œæ¨¡å‹")
                    
            else:
                st.error("æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
                
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹æ³¨å†Œä¿¡æ¯å¤±è´¥: {e}")
    
    def _show_model_details(self, model: Dict[str, Any]):
        """æ˜¾ç¤ºæ¨¡å‹è¯¦æƒ…"""
        
        st.subheader(f"ğŸ“Š æ¨¡å‹è¯¦æƒ…: {model['name']}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**åŸºæœ¬ä¿¡æ¯:**")
            st.write(f"- æ¨¡å‹åç§°: {model.get('name', 'N/A')}")
            st.write(f"- æè¿°: {model.get('description', 'N/A')}")
            creation_time = datetime.fromtimestamp(model.get('creation_timestamp', 0) / 1000)
            st.write(f"- åˆ›å»ºæ—¶é—´: {creation_time.strftime('%Y-%m-%d %H:%M')}")
        
        with col2:
            st.write("**æ ‡ç­¾ä¿¡æ¯:**")
            tags = model.get("tags", {})
            if tags:
                for key, value in tags.items():
                    st.write(f"- {key}: {value}")
            else:
                st.write("- æ— æ ‡ç­¾")
        
        # ç‰ˆæœ¬ä¿¡æ¯
        st.write("**ç‰ˆæœ¬ä¿¡æ¯:**")
        versions = model.get("latest_versions", [])
        if versions:
            version_data = []
            for version in versions:
                creation_time = datetime.fromtimestamp(version.get('creation_timestamp', 0) / 1000)
                version_data.append({
                    "ç‰ˆæœ¬": version.get("version", ""),
                    "é˜¶æ®µ": version.get("stage", ""),
                    "æè¿°": version.get("description", ""),
                    "åˆ›å»ºæ—¶é—´": creation_time.strftime("%Y-%m-%d %H:%M"),
                    "è¿è¡ŒID": version.get("run_id", "")[:8] + "..." if version.get("run_id") else ""
                })
            
            versions_df = pd.DataFrame(version_data)
            st.dataframe(versions_df, use_container_width=True)
        else:
            st.write("- æ— ç‰ˆæœ¬ä¿¡æ¯")
    
    def _render_model_versions(self):
        """æ¸²æŸ“æ¨¡å‹ç‰ˆæœ¬ç®¡ç†"""
        
        st.subheader("ğŸ”„ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†")
        
        # è·å–æ¨¡å‹åˆ—è¡¨
        try:
            response = requests.get(f"{self.api_base_url}/mlflow/models")
            
            if response.status_code == 200:
                models = response.json()["data"]
                
                if models:
                    selected_model = st.selectbox(
                        "é€‰æ‹©æ¨¡å‹",
                        options=[model["name"] for model in models],
                        key="version_model_selector"
                    )
                    
                    if selected_model:
                        # è·å–æ¨¡å‹ç‰ˆæœ¬
                        versions_response = requests.get(
                            f"{self.api_base_url}/mlflow/models/{selected_model}/versions"
                        )
                        
                        if versions_response.status_code == 200:
                            versions = versions_response.json()["data"]
                            
                            if versions:
                                # ç‰ˆæœ¬ç»Ÿè®¡
                                col1, col2, col3, col4 = st.columns(4)
                                
                                with col1:
                                    st.metric("æ€»ç‰ˆæœ¬æ•°", len(versions))
                                
                                with col2:
                                    production_count = len([v for v in versions if v["stage"] == "Production"])
                                    st.metric("ç”Ÿäº§ç‰ˆæœ¬", production_count)
                                
                                with col3:
                                    staging_count = len([v for v in versions if v["stage"] == "Staging"])
                                    st.metric("æµ‹è¯•ç‰ˆæœ¬", staging_count)
                                
                                with col4:
                                    archived_count = len([v for v in versions if v["stage"] == "Archived"])
                                    st.metric("å½’æ¡£ç‰ˆæœ¬", archived_count)
                                
                                # ç‰ˆæœ¬åˆ—è¡¨
                                st.subheader("ğŸ“‹ ç‰ˆæœ¬åˆ—è¡¨")
                                
                                version_data = []
                                for version in versions:
                                    creation_time = datetime.fromtimestamp(
                                        version.get("creation_timestamp", 0) / 1000
                                    ).strftime("%Y-%m-%d %H:%M")
                                    
                                    version_data.append({
                                        "ç‰ˆæœ¬": version.get("version", ""),
                                        "é˜¶æ®µ": version.get("stage", ""),
                                        "æè¿°": version.get("description", ""),
                                        "åˆ›å»ºæ—¶é—´": creation_time,
                                        "è¿è¡ŒID": version.get("run_id", "")[:12] + "..." if version.get("run_id") else "",
                                        "æ ‡ç­¾æ•°": len(version.get("tags", {}))
                                    })
                                
                                versions_df = pd.DataFrame(version_data)
                                st.dataframe(versions_df, use_container_width=True)
                                
                                # é˜¶æ®µæ›´æ–°
                                self._render_stage_update_form(selected_model, versions)
                                
                                # ç‰ˆæœ¬è¶‹åŠ¿å›¾
                                self._render_version_trends(versions)
                            
                            else:
                                st.info(f"æ¨¡å‹ {selected_model} æš‚æ— ç‰ˆæœ¬")
                        else:
                            st.error("æ— æ³•è·å–æ¨¡å‹ç‰ˆæœ¬")
                
                else:
                    st.info("æš‚æ— æ³¨å†Œæ¨¡å‹")
                    
            else:
                st.error("æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
                
        except Exception as e:
            st.error(f"è·å–æ¨¡å‹ç‰ˆæœ¬ä¿¡æ¯å¤±è´¥: {e}")
    
    def _render_stage_update_form(self, model_name: str, versions: List[Dict]):
        """æ¸²æŸ“é˜¶æ®µæ›´æ–°è¡¨å•"""
        
        st.subheader("ğŸ”„ æ›´æ–°æ¨¡å‹é˜¶æ®µ")
        
        with st.form("update_stage_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                selected_version = st.selectbox(
                    "é€‰æ‹©ç‰ˆæœ¬",
                    options=[v["version"] for v in versions],
                    key="stage_version_selector"
                )
            
            with col2:
                new_stage = st.selectbox(
                    "æ–°é˜¶æ®µ",
                    options=["None", "Staging", "Production", "Archived"],
                    key="new_stage_selector"
                )
            
            submitted = st.form_submit_button("ğŸš€ æ›´æ–°é˜¶æ®µ")
            
            if submitted and selected_version and new_stage:
                try:
                    response = requests.post(
                        f"{self.api_base_url}/mlflow/models/{model_name}/versions/{selected_version}/stage",
                        params={"stage": new_stage}
                    )
                    
                    if response.status_code == 200:
                        st.success(f"âœ… æ¨¡å‹ {model_name} ç‰ˆæœ¬ {selected_version} é˜¶æ®µæ›´æ–°ä¸º {new_stage}ï¼")
                        st.rerun()
                    else:
                        st.error(f"âŒ æ›´æ–°å¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"âŒ æ›´æ–°é˜¶æ®µå¤±è´¥: {e}")
    
    def _render_version_trends(self, versions: List[Dict]):
        """æ¸²æŸ“ç‰ˆæœ¬è¶‹åŠ¿å›¾"""
        
        st.subheader("ğŸ“ˆ ç‰ˆæœ¬è¶‹åŠ¿")
        
        # æŒ‰é˜¶æ®µç»Ÿè®¡
        stage_counts = {}
        for version in versions:
            stage = version.get("stage", "None")
            stage_counts[stage] = stage_counts.get(stage, 0) + 1
        
        if stage_counts:
            fig_stages = px.pie(
                values=list(stage_counts.values()),
                names=list(stage_counts.keys()),
                title="ç‰ˆæœ¬é˜¶æ®µåˆ†å¸ƒ"
            )
            st.plotly_chart(fig_stages, use_container_width=True)
        
        # æ—¶é—´è¶‹åŠ¿
        if len(versions) > 1:
            version_times = []
            for version in versions:
                creation_time = datetime.fromtimestamp(version.get("creation_timestamp", 0) / 1000)
                version_times.append({
                    "ç‰ˆæœ¬": version.get("version", ""),
                    "åˆ›å»ºæ—¶é—´": creation_time,
                    "é˜¶æ®µ": version.get("stage", "None")
                })
            
            version_times_df = pd.DataFrame(version_times)
            version_times_df = version_times_df.sort_values("åˆ›å»ºæ—¶é—´")
            
            fig_timeline = px.scatter(
                version_times_df,
                x="åˆ›å»ºæ—¶é—´",
                y="ç‰ˆæœ¬",
                color="é˜¶æ®µ",
                title="ç‰ˆæœ¬åˆ›å»ºæ—¶é—´çº¿",
                hover_data=["é˜¶æ®µ"]
            )
            st.plotly_chart(fig_timeline, use_container_width=True)
    
    def _render_model_metrics(self):
        """æ¸²æŸ“æ¨¡å‹æŒ‡æ ‡"""
        
        st.subheader("ğŸ“ˆ æ¨¡å‹æŒ‡æ ‡ç®¡ç†")
        
        # æŒ‡æ ‡è®°å½•è¡¨å•
        st.subheader("ğŸ“ è®°å½•æ¨¡å‹æŒ‡æ ‡")
        
        with st.form("log_metrics_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                model_name = st.text_input("æ¨¡å‹åç§°", placeholder="chicago-taxi-fare-predictor")
                model_version = st.text_input("æ¨¡å‹ç‰ˆæœ¬", placeholder="1")
            
            with col2:
                metric_name = st.text_input("æŒ‡æ ‡åç§°", placeholder="rmse")
                metric_value = st.number_input("æŒ‡æ ‡å€¼", value=0.0, format="%.4f")
            
            submitted = st.form_submit_button("ğŸ“Š è®°å½•æŒ‡æ ‡")
            
            if submitted and model_name and model_version and metric_name:
                try:
                    payload = {
                        "model_name": model_name,
                        "model_version": model_version,
                        "metrics": {metric_name: metric_value}
                    }
                    
                    response = requests.post(
                        f"{self.api_base_url}/mlflow/models/metrics",
                        json=payload
                    )
                    
                    if response.status_code == 200:
                        st.success(f"âœ… æŒ‡æ ‡è®°å½•æˆåŠŸï¼")
                        st.json(response.json())
                    else:
                        st.error(f"âŒ è®°å½•å¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"âŒ è®°å½•æŒ‡æ ‡å¤±è´¥: {e}")
        
        # æ¨¡æ‹ŸæŒ‡æ ‡å¯è§†åŒ–
        self._render_metrics_visualization()
    
    def _render_metrics_visualization(self):
        """æ¸²æŸ“æŒ‡æ ‡å¯è§†åŒ–"""
        
        st.subheader("ğŸ“Š æ¨¡å‹æ€§èƒ½æŒ‡æ ‡")
        
        # ç”Ÿæˆæ¨¡æ‹ŸæŒ‡æ ‡æ•°æ®
        metrics_data = self._generate_mock_metrics()
        
        col1, col2 = st.columns(2)
        
        with col1:
            # RMSE è¶‹åŠ¿
            fig_rmse = px.line(
                metrics_data,
                x="ç‰ˆæœ¬",
                y="RMSE",
                title="RMSE è¶‹åŠ¿",
                markers=True
            )
            st.plotly_chart(fig_rmse, use_container_width=True)
        
        with col2:
            # å‡†ç¡®ç‡è¶‹åŠ¿
            fig_accuracy = px.line(
                metrics_data,
                x="ç‰ˆæœ¬",
                y="å‡†ç¡®ç‡",
                title="å‡†ç¡®ç‡è¶‹åŠ¿",
                markers=True
            )
            st.plotly_chart(fig_accuracy, use_container_width=True)
        
        # æŒ‡æ ‡å¯¹æ¯”
        st.subheader("ğŸ“ˆ ç‰ˆæœ¬æŒ‡æ ‡å¯¹æ¯”")
        
        fig_comparison = make_subplots(
            rows=1, cols=2,
            subplot_titles=("RMSE å¯¹æ¯”", "å‡†ç¡®ç‡å¯¹æ¯”"),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        fig_comparison.add_trace(
            go.Bar(x=metrics_data["ç‰ˆæœ¬"], y=metrics_data["RMSE"], name="RMSE"),
            row=1, col=1
        )
        
        fig_comparison.add_trace(
            go.Bar(x=metrics_data["ç‰ˆæœ¬"], y=metrics_data["å‡†ç¡®ç‡"], name="å‡†ç¡®ç‡"),
            row=1, col=2
        )
        
        fig_comparison.update_layout(height=400, showlegend=False)
        st.plotly_chart(fig_comparison, use_container_width=True)
    
    def _generate_mock_metrics(self) -> pd.DataFrame:
        """ç”Ÿæˆæ¨¡æ‹ŸæŒ‡æ ‡æ•°æ®"""
        
        versions = ["v1", "v2", "v3", "v4"]
        rmse_values = [3.2, 2.8, 2.1, 1.9]
        accuracy_values = [0.85, 0.89, 0.92, 0.94]
        
        return pd.DataFrame({
            "ç‰ˆæœ¬": versions,
            "RMSE": rmse_values,
            "å‡†ç¡®ç‡": accuracy_values
        })
    
    def _render_model_prediction(self):
        """æ¸²æŸ“æ¨¡å‹é¢„æµ‹"""
        
        st.subheader("ğŸš€ æ¨¡å‹é¢„æµ‹æµ‹è¯•")
        
        # é¢„æµ‹è¡¨å•
        with st.form("model_prediction_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                model_name = st.text_input("æ¨¡å‹åç§°", value="chicago-taxi-fare-predictor")
                model_version = st.text_input("æ¨¡å‹ç‰ˆæœ¬", value="latest")
                model_stage = st.selectbox("æ¨¡å‹é˜¶æ®µ", ["Production", "Staging", "None"])
            
            with col2:
                st.write("**è¾“å…¥ç‰¹å¾:**")
                trip_distance = st.number_input("è¡Œç¨‹è·ç¦»", value=3.5, min_value=0.1)
                passenger_count = st.number_input("ä¹˜å®¢æ•°", value=2, min_value=1, max_value=6)
                pickup_hour = st.number_input("ä¸Šè½¦å°æ—¶", value=14, min_value=0, max_value=23)
            
            submitted = st.form_submit_button("ğŸ¯ å¼€å§‹é¢„æµ‹")
            
            if submitted and model_name:
                try:
                    payload = {
                        "model_name": model_name,
                        "model_version": model_version,
                        "model_stage": model_stage,
                        "input_data": {
                            "trip_distance": trip_distance,
                            "passenger_count": passenger_count,
                            "pickup_hour": pickup_hour
                        }
                    }
                    
                    response = requests.post(
                        f"{self.api_base_url}/mlflow/models/predict",
                        json=payload
                    )
                    
                    if response.status_code == 200:
                        result = response.json()["data"]
                        
                        st.success("âœ… é¢„æµ‹æˆåŠŸï¼")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("é¢„æµ‹è´¹ç”¨", f"${result['prediction']:.2f}")
                        
                        with col2:
                            st.metric("ç½®ä¿¡åº¦", f"{result['confidence']:.2%}")
                        
                        with col3:
                            st.metric("æ¨¡å‹ç‰ˆæœ¬", result['model_version'])
                        
                        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                        st.subheader("ğŸ“Š é¢„æµ‹è¯¦æƒ…")
                        st.json(result)
                        
                    else:
                        st.error(f"âŒ é¢„æµ‹å¤±è´¥: {response.text}")
                        
                except Exception as e:
                    st.error(f"âŒ é¢„æµ‹å¤±è´¥: {e}")


# å…¨å±€å®ä¾‹
mlflow_ui = MLflowUIIntegration()
